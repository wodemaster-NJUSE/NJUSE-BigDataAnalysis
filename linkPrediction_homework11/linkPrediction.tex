\documentclass{article}

\usepackage{amsmath} % ç”¨äºæ•°å­¦å…¬å¼
\usepackage{graphicx} % ç”¨äºæ’å…¥å›¾ç‰‡
\usepackage{lipsum} % ç”¨äºç”Ÿæˆè™šæ‹Ÿæ–‡æœ¬
\usepackage{ctex} % å¯¼å…¥ ctex åŒ…ä»¥æ”¯æŒä¸­æ–‡
\usepackage{titlesec} % å¯¼å…¥ titlesec åŒ…ä»¥å®šåˆ¶æ ‡é¢˜æ ·å¼
\usepackage{fontspec} % ç”¨äºè®¾ç½®ä¸­æ–‡å­—ä½“

\setmainfont{SimSun} % è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ŒSimSun ä¸ºå®‹ä½“çš„ç³»ç»Ÿå­—ä½“

\title{LinkPredictionå®éªŒ}
\author{ç¨‹æ™ºé•ã€é™ˆå‡Œ}
\date{\today}

\begin{document}
\maketitle

\section*{ä½œä¸šä»»åŠ¡}
\begin{itemize}
    \item ä»ä»£ç ï¼ˆè‡ªå·±å®ç°orå¤ç°ï¼‰ã€æ•°æ®é›†ï¼ˆç›´æ¥è·å–æˆ–è‡ªå·±å¤„ç†å¾—åˆ°ï¼‰ä¸¤ä¸ªè§’åº¦æƒè¡¡æ˜¯å¦é€‰æ‹©æŸä¸ªlink predictionçš„å·¥ä½œã€‚ã€‚
    \item è®ºæ–‡æ‘˜è¦abstractå’Œintroductionç¿»è¯‘
    \item é—®é¢˜æè¿°ã€‚
    \item è¾“å…¥ã€è¾“å‡ºã€æ¨¡å‹ç®—æ³•æè¿°ï¼ˆé™„æ¡†æ¶å›¾ï¼›æœ‰å¤šä¸ªçš„æŒ‘1ä¸ªä¸»è¦å®ç°ï¼‰
    \item è¯„ä»·æŒ‡æ ‡åŠå…¶è®¡ç®—å…¬å¼
    \item å¯¹æ¯”æ–¹æ³•åŠè¿™äº›å¯¹æ¯”æ–¹æ³•çš„å¼•ç”¨è®ºæ–‡å‡ºå¤„
    \item ç»“æœ
    \item æ‰“åŒ…æäº¤codeã€è¿è¡Œé…ç½®è¯´æ˜ï¼ˆæ•°æ®é›†å¤ªå¤§çš„å¯ä»¥æ˜¯å¼€æ”¾é“¾æ¥ï¼Œéœ€æè¿°ï¼‰
\end{itemize}
\section*{å®éªŒéš¾ç‚¹ï¼š}
\begin{itemize}
    \item è®ºæ–‡ä¸ºå…¨è‹±æ–‡æè¿°ï¼Œé˜…è¯»éš¾åº¦æå‡
    \item è®ºæ–‡å®éªŒå¤ç°ç¯å¢ƒæ­é…
    \item ç›¸å…³ç¥ç»ç½‘ç»œã€æœºå™¨å­¦ä¹ ã€å›¾è®ºçš„çŸ¥è¯†æš‚ä¸”æœªçŸ¥
\end{itemize}
\section*{è®ºæ–‡ï¼šSampling Enclosing Subgraphs for Link Prediction}
\subsection*{abstractå’Œintroductionç¿»è¯‘}
\textbf{ABSTRACT
Link prediction is a fundamental problem for graph-structured data
(e.g., social networks, drug side-effect networks, etc.). Graph neural
networks have offered robust solutions for this problem, specifically by learning the representation of the subgraph enclosing the
target link (i.e., pair of nodes). However, these solutions do not
scale well to large graphs as extraction and operation on enclosing subgraphs are computationally expensive, especially for large
graphs. This paper presents a scalable link prediction solution, that
we call ScaLed, which utilizes sparse enclosing subgraphs to make
predictions. To extract sparse enclosing subgraphs, ScaLed takes
multiple random walks from a target pair of nodes, then operates
on the sampled enclosing subgraph induced by all visited nodes.
By leveraging the smaller sampled enclosing subgraph, ScaLed
can scale to larger graphs with much less overhead while maintaining high accuracy. ScaLed further provides the flexibility to
control the trade-off between computation overhead and accuracy.
Through comprehensive experiments, we have shown that ScaLed
can produce comparable accuracy to those reported by the existing subgraph representation learning frameworks while being less
computationally demanding.}\\

\textbf{æ‘˜è¦ï¼šé“¾æ¥é¢„æµ‹æ˜¯å›¾ç»“æ„æ•°æ®ï¼ˆä¾‹å¦‚ç¤¾äº¤ç½‘ç»œã€è¯ç‰©å‰¯ä½œç”¨ç½‘ç»œç­‰ï¼‰çš„ä¸€ä¸ªåŸºæœ¬é—®é¢˜ã€‚å›¾ç¥ç»ç½‘ç»œä¸ºè¿™ä¸ªé—®é¢˜æä¾›äº†é²æ£’çš„è§£å†³æ–¹æ¡ˆï¼Œå°¤å…¶æ˜¯é€šè¿‡å¯¹åŒ…å«ç›®æ ‡é“¾æ¥ï¼ˆå³èŠ‚ç‚¹å¯¹ï¼‰çš„å­å›¾çš„è¡¨ç¤ºçš„å­¦ä¹ ã€‚ç„¶è€Œï¼Œè¿™äº›è§£å†³æ–¹æ¡ˆä¸èƒ½å¾ˆå¥½åœ°æ‰©å±•åˆ°å¤§å‹å›¾ï¼Œå› ä¸ºå¯¹å°é—­å­å›¾çš„æå–å’Œæ“ä½œåœ¨è®¡ç®—ä¸Šæ˜¯æ˜‚è´µçš„ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¯æ‰©å±•çš„é“¾æ¥é¢„æµ‹è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºScaLedï¼Œå®ƒåˆ©ç”¨ç¨€ç–å°é—­å­å›¾è¿›è¡Œé¢„æµ‹ã€‚ä¸ºäº†æå–ç¨€ç–å°é—­å­å›¾ï¼ŒScaLedä»ç›®æ ‡èŠ‚ç‚¹å¯¹å¼€å§‹è¿›è¡Œå¤šæ¬¡éšæœºåœ°æ¸¸èµ°ï¼Œç„¶åå¯¹æ‰€æœ‰è®¿é—®èŠ‚ç‚¹äº§ç”Ÿçš„é‡‡æ ·å°é—­å­å›¾è¿›è¡Œæ“ä½œã€‚é€šè¿‡åˆ©ç”¨è¾ƒå°çš„é‡‡æ ·å°é—­å­å›¾ï¼ŒScaLedå¯ä»¥åœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶ä»¥æ›´å°‘çš„å¼€é”€æ‰©å±•åˆ°æ›´å¤§çš„å›¾ã€‚é€šè¿‡å…¨é¢çš„å®éªŒï¼Œæˆ‘ä»¬è¡¨æ˜ScaLedå¯ä»¥è¾¾åˆ°é‚£äº›ç°æœ‰çš„å­å›¾è¡¨ç¤ºå­¦ä¹ æ¡†æ¶æ‰€æŠ¥å‘Šçš„ç²¾åº¦ï¼ŒåŒæ—¶æ‹¥æœ‰è¾ƒä½çš„è®¡ç®—è¦æ±‚ã€‚}\\

\textbf{INTRODUCTION
Graph-structured data such as user interactions, collaborations,
protein-protein interactions, drug-drug interactions are prevalent in
natural and social sciences. Link predictionâ€”a fundamental problem
on graph-structured dataâ€”intends to quantify the likelihood of a
link (or interaction) occurring between a pair of nodes (e.g., proteins,
drugs, etc.). Link prediction has many diverse applications such as
predicting drug side effects, drug-repurposing [14], understanding
molecule interactions [18], friendship recommendation [9], and
recommender systems [39].
Many solutions to link prediction problem [24, 26â€“28, 35] has
been proposed ranging from simple heuristics (e.g., common neighbors, Adamic-Adar [1], Katz [19]) to graph neural networks (GNNs)
[5, 6, 17, 21, 30, 45]. Among these solutions, GNNs [15, 36, 48]
have emerged as the widely-accepted and successful solution for
learning rich latent representations of graph data to tackle link
prediction problems. The early GNNs focused on shallow encoders
[13, 32] in which the latent nodesâ€™ representations was first learnt
through a sequence of random walks, and then a likelihood of a
link is determined by combining its two-end nodesâ€™ latent representations. However, these shallow encoders were limited by not
incorporating nodal features and their incompatibility with inductive settings as they require that all nodes are present for training.
These two challenges were (partially) addressed with the emergence of message-passing graph neural networks [16, 22, 37]. These
advancements motivate the research on determining and extending
the expressive power of GNNs [3, 12, 40â€“42, 46] for all downstream
tasks of link prediction, node classification, and graph classification.
For link prediction, subgraph-based representation learning (SGRL)
methods [5, 6, 25, 30, 45]â€”by learning the enclosing subgraphs
around the two-end nodes rather than independently learning two
end-nodeâ€™s embeddingâ€”have improved GNNs expressive power,
and offered state-of-the-art solutions. However, these solutions suffer from the lack of scalability, thus preventing them to be applied
to large-scale graphs. This is primarily due to the computation
overhead in extracting, preprocessing, and learning (large) enclosing subgraphs for any pair of nodes. We focus on addressing this
scalability issue.
Contribution. We introduce Sampling Enclosing Subgraph for Link
Prediction (ScaLed) to extend SGRL methods and enhance their scalability. The crux of ScaLed is to sample enclosing subgraphs using
a sequence of random walks. This sampling reduces the computational overhead of large subgraphs while maintaining their key
structural information. ğ‘†ğ‘ğ‘ğ¿ğ‘’ğ‘‘ can be integrated into any GNN,
and also offers parallelizability and model compression that can be
exploited for large-scale graphs. Furthermore, the two hyperparameters, walk length and number of walks, in ScaLed provides a way
to control the trade-off between scalability and accuracy, if needed.
Our extensive experiments on real-world datasets demonstrate that
ScaLed produces comparable results to the state-of-the-art methods
(e.g, SEAL [45]) in link prediction, but requiring magnitudes less
training data, time, and memory. ScaLed combines the benefits of
SGRL framework and random walks for link prediction.
}\\
\textbf{å¼•è¨€ï¼šç”¨æˆ·äº¤äº’åä½œã€è›‹ç™½è´¨é—´ç›¸äº’ä½œç”¨ã€è¯ç‰©é—´ç›¸äº’ä½œç”¨ç­‰å›¾ç»“æ„æ•°æ®åœ¨è‡ªç„¶ç§‘å­¦å’Œç¤¾ä¼šç§‘å­¦ä¸­æ™®éå­˜åœ¨ã€‚é“¾æ¥é¢„æµ‹â€”â€”å›¾ç»“æ„æ•°æ®çš„ä¸€ä¸ªåŸºæœ¬é—®é¢˜â€”â€”æ—¨åœ¨é‡åŒ–ä¸€å¯¹èŠ‚ç‚¹ï¼ˆä¾‹å¦‚è›‹ç™½è´¨ã€è¯ç‰©ç­‰ï¼‰ä¹‹é—´äº§ç”Ÿé“¾æ¥ï¼ˆæˆ–äº¤äº’ï¼‰çš„å¯èƒ½æ€§ã€‚é“¾æ¥é¢„æµ‹æœ‰è®¸å¤šä¸åŒçš„åº”ç”¨ï¼Œä¾‹å¦‚é¢„æµ‹è¯ç‰©å‰¯ä½œç”¨ã€è¯ç‰©é‡æ–°åˆ©ç”¨ã€ç†è§£åˆ†å­é—´çš„ç›¸äº’ä½œç”¨å’Œæ¨èç³»ç»Ÿã€‚äººä»¬å·²ç»æå‡ºäº†è®¸å¤šé“¾æ¥é¢„æµ‹é—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼Œä»ç®€å•çš„å¯å‘å¼æ–¹æ³•ï¼ˆä¾‹å¦‚å…±åŒé‚»å±…ã€Adamic-Adarã€Katzï¼‰åˆ°å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰ã€‚åœ¨è¿™äº›è§£å†³æ–¹æ¡ˆä¸­ï¼ŒGNNå·²ç»æˆä¸ºäº†å­¦ä¹ å›¾æ•°æ®çš„ä¸°å¯Œæ½œåœ¨è¡¨ç¤ºä»¥è§£å†³é“¾æ¥é¢„æµ‹é—®é¢˜çš„å‰æ™¯è‰¯å¥½çš„è§£å†³æ–¹æ¡ˆã€‚æ—©æœŸçš„GNNä¸“æ³¨äºæµ…å±‚ç¼–ç å™¨ï¼Œå…¶ä¸­æ½œåœ¨èŠ‚ç‚¹çš„è¡¨ç¤ºé¦–å…ˆé€šè¿‡ä¸€ç³»åˆ—éšæœºæ¸¸èµ°æ¥è·å–ï¼Œç„¶åé€šè¿‡ç»„åˆå…¶ä¸¤ç«¯èŠ‚ç‚¹çš„æ½œåœ¨è¡¨ç¤ºæ¥ç¡®å®šé“¾æ¥çš„å¯èƒ½æ€§ã€‚ç„¶è€Œï¼Œè¿™äº›æµ…å±‚ç¼–ç å™¨å› æœªç»“åˆèŠ‚ç‚¹ç‰¹å¾ä¸”ä¸æ„Ÿåº”è®¾ç½®ä¸å…¼å®¹è€Œå—åˆ°é™åˆ¶ã€‚è¿™ä¸¤ä¸ªé—®é¢˜å·²ï¼ˆéƒ¨åˆ†ï¼‰é€šè¿‡æ¶ˆæ¯ä¼ é€’å›¾ç¥ç»ç½‘ç»œå¾—åˆ°è§£å†³ã€‚è¿™äº›è¿›æ­¥æ¿€å‘äº†å…³äºç¡®å®šå’Œæ‰©å±•GNNå¯¹äºé“¾è·¯é¢„æµ‹ã€èŠ‚ç‚¹åˆ†ç±»å’Œå›¾åˆ†ç±»ç­‰æ‰€æœ‰ä¸‹æ¸¸ä»»åŠ¡çš„è¡¨è¾¾èƒ½åŠ›çš„ç ”ç©¶ã€‚å¯¹äºé“¾æ¥é¢„æµ‹ï¼ŒåŸºäºå­å›¾çš„è¡¨ç¤ºå­¦ä¹ (SGRL)æ–¹æ³•â€”â€”é€šè¿‡å­¦ä¹ ä¸¤ç«¯èŠ‚ç‚¹å‘¨å›´çš„å°é—­å­å›¾ï¼Œè€Œä¸æ˜¯ç‹¬ç«‹å­¦ä¹ ä¸¤ç«¯èŠ‚ç‚¹çš„åµŒå…¥â€”â€”æé«˜äº† GNN çš„è¡¨è¾¾èƒ½åŠ›ï¼Œå¹¶æä¾›äº†æœ€å…ˆè¿›çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œè¿™äº›è§£å†³æ–¹æ¡ˆç¼ºä¹å¤§è§„æ¨¡å›¾çš„å¯æ‰©å±•æ€§ã€‚è¿™ä¸»è¦æ˜¯ç”±äºæå–ã€é¢„å¤„ç†å’Œå­¦ä¹ ï¼ˆå¤§ï¼‰å°é—­å­å›¾çš„è®¡ç®—å¼€é”€ã€‚æˆ‘ä»¬å¼•å…¥äº†ç”¨äºé“¾è·¯é¢„æµ‹çš„é‡‡æ ·å°é—­å­å›¾ï¼ˆScaLedï¼‰æ¥æ‰©å±• SGRL æ–¹æ³•å¹¶å¢å¼ºå…¶å¯æ‰©å±•æ€§ã€‚ScaLedä½¿ç”¨ä¸€ç³»åˆ—éšæœºæ¸¸èµ°å¯¹å°é—­å­å›¾è¿›è¡Œé‡‡æ ·ã€‚è¿™ç§é‡‡æ ·å‡å°‘äº†å¤§å‹å­å›¾çš„è®¡ç®—å¼€é”€ï¼ŒåŒæ—¶ä¿ç•™äº†å…³é”®çš„ç»“æ„ä¿¡æ¯ã€‚ScaLedå¯ä»¥é›†æˆåˆ°ä»»ä½•GNNä¸­ï¼Œå¹¶ä¸”è¿˜æä¾›äº†å¯ç”¨äºå¤§è§„æ¨¡å›¾çš„å¹¶è¡Œæ€§å’Œæ¨¡å‹å‹ç¼©ã€‚å¦‚æœéœ€è¦ï¼ŒScaLed ä¸­çš„ä¸¤ä¸ªè¶…å‚æ•°ï¼ˆæ­¥è¡Œé•¿åº¦å’Œæ­¥è¡Œæ¬¡æ•°ï¼‰æä¾›äº†ä¸€ç§æ§åˆ¶å¯æ‰©å±•æ€§å’Œå‡†ç¡®æ€§ä¹‹é—´çš„æƒè¡¡çš„æ–¹æ³•ã€‚æˆ‘ä»¬å¯¹çœŸå®ä¸–ç•Œæ•°æ®é›†çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒScaLedåœ¨é“¾è·¯é¢„æµ‹ä¸­äº§ç”Ÿçš„ç»“æœä¸æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ˆä¾‹å¦‚ SEALï¼‰ç›¸å½“ï¼Œä½†éœ€è¦çš„è®­ç»ƒæ•°æ®ã€æ—¶é—´å’Œå†…å­˜è¦å°‘å¾—å¤šã€‚}
\section*{é—®é¢˜æè¿°}
è¯¥è®ºæ–‡ä¸»è¦
\end{document}